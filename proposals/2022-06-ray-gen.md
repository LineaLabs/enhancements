# Summary

Ray is a popular framework for distributed execution. This proposal explores 
how we could use the LineaPy graph to automatically leverage Ray in a data
science script that does not already use Ray.

## General Motivation

To help data scientists leverage Ray could mean speeding up executions 
and unlocking data of new scale.

It may not be easy to use Ray, as the data scientists have to learn a new framework, and develop a mental model for when to use the distributed tasks and actors.  If we could automate the majority of the reasoning with logic over the LineaPy graph, we could lower the barrier to entry.

## Motivating and Specifying Examples

There are a few levels of modifications that we could be making to the user 
code. In these examples, we'll start with the most basic modifications---annotating functions as tasks and calling the results with `.remote()`, as opposed to making deeper refactors, such as some in the [anti-pattern docs](https://docs.ray.io/en/releases-1.8.0/ray-design-patterns/index.html).

### Tasks

Taking a simple example from the [Ray documentation](https://docs.ray.io/en/master/ray-core/tasks.html#ray-remote-functions):

```python
@ray.remote
def slow_function():
    time.sleep(10)
    print(1)

for _ in range(4):
    slow_function.remote()
```

The non-Ray equivalent of this toy code would be

```python
def slow_function():
    time.sleep(10)
    print(1)

for _ in range(4):
    slow_function()
```

In additional to one step parallelization, Ray could also create a dag of 
remote/asynchronous computations of the following form

```python
@ray.remote
def function_with_an_argument(value):
    return value + 1

obj_ref1 = my_function.remote()
assert ray.get(obj_ref1) == 1

# You can pass an object ref as an argument to another Ray remote function.
obj_ref2 = function_with_an_argument.remote(obj_ref1)
assert ray.get(obj_ref2) == 2
```

For now, these two examples already suggest a few minimum requirements to achieve a sensible transformation. Broadly, we would have to figure out a few
 properties of the functions and their invocations.

1. [P1] Do the functions have any shared state. Here is an [(anti)example from the docs](https://docs.ray.io/en/releases-1.8.0/ray-design-patterns/unnecessary-ray-get.html), where global variables are used.

```python
import ray
global_v = 3

@ray.remote
class A:
    def f(self):
        return global_v + 3

actor = A.remote()
global_v = 4
# This prints 6, not 7. It is because the value  change of global_v inside a driver is not
# reflected to the actor because they are running in different processes.
print(ray.get(actor.f.remote()))
```

2. [P2] We need to identify "slow" functions that's _worth_ parallelizing. 
Per [the docs](https://docs.ray.io/en/releases-1.8.0/ray-design-patterns/fine-grained-tasks.html), it would be counter-productive to parallelize _all_ functions. If we make a mistake here, it won't be an immediate deal breaker, since the program can still execute. There are a few more performance based optimizations,
   - [using `ray.pyt`](https://docs.ray.io/en/releases-1.8.0/ray-design-patterns/closure-capture.html)



#### Actors

Actors is more advanced and requires instrumentation of classes, which LineaPy does not currently model. We'll revisit actors at a later time.

## Design and Architecture

There are a few types of changes

- [LineaPy side] Lineapy graph has to add to have more rich language
  representations:
  - LineaPy needs to represent function definition as first class (we might be 
    able to take some short cuts),
      - We would also be able to create function definitions (to use the annotations)
  - We will also need control flows represented, since most parallelization
    happens in the context of loops (TODO: fact check). Currently, we have a 
    crude "black box" abstraction).


- Figuring out what APIs, or intermediate representations (IRs) we would need 
  for the Ray folks to figure out what Ray decorations to add. For instance,
  one such information could be at the level of having a function that contains
  the invocation of `train` etc.
  - We will need more robust refactoring mechanisms to create
  meaningful grouping of script calls to decorate.



## Discussion items

- [ ] Add more examples that can help flush out the kind of information we need for Ray code gen. E.g., mutation behaviors, invocation patterns.
  - Specifically, want to walk through common language patterns in data science
  that has mutations patterns that's not compatible with Ray's model.
    - Can use [our demo](https://github.com/LineaLabs/demos/blob/main/story/clean_up_a_messy_notebook/clean_up_a_messy_notebook.ipynb).
       - Identify what part of the code could benefit from parallelization?
       - What if we just made all functions `.remote` in our demo notebooks?
       - I assume Ray doesn't work when it's just all scripts, right?

- [ ] How often do users use [advanced patterns in the docs](https://docs.ray.io/en/releases-1.8.0/ray-design-patterns/concurrent-operations-async-actor.html)?

- [ ] It might be easier if we didn't use code-generation, but directly invoked
      the executions with our graph nodes. However the downside is flexibility for the user to change (both our mistakes if any, and their custom requirements).
    